services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
      target: node
    user: "2001:2001"
    environment:
      - MONGO_URI=${MONGO_URI}
    volumes:
      - type: bind
        source: ./librechat.yaml
        target: /app/librechat.yaml
      - type: bind
        source: .env
        target: /app/.env
      - type: bind
        source: /data/LibreChat/images
        target: /app/client/public/images
      - type: bind
        source: /data/LibreChat/uploads
        target: /app/uploads
      - type: bind
        source: /data/LibreChat/logs
        target: /app/api/logs
    #  - /data/LibreChat/certs/azure-chain.crt:/usr/local/share/ca-certificates/azure-chain.crt
    #command: sh -c "cat /usr/local/share/ca-certificates/*.crt >> /etc/ssl/certs/ca-certificates.crt && /usr/local/bin/npm run backend"
  rag_api:
    build:
      context: ../rag_api
      dockerfile: Dockerfile
    
    
  mongodb:
    user: "2001:2001"
    ports:
      - "27017:27017"
    volumes:
      - /data/LibreChat/data-node:/data/db
  meilisearch:
    user: "2001:2001"
    volumes:
      - /data/LibreChat/meili_data_v1.12:/meili_data
  vectordb:
    volumes:
    - pgdata2:/var/lib/postgresql/data
volumes:
  pgdata2:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/LibreChat/pgdata2
# ---------------------------------------------------

# services:

# # USE LIBRECHAT CONFIG FILE
#   api:
#     volumes:
#     - type: bind
#       source: ./librechat.yaml
#       target: /app/librechat.yaml

# # LOCAL BUILD
#   api:
#     image: librechat
#     build:
#       context: .
#       target: node

# # BUILD FROM LATEST IMAGE
#   api:
#     image: ghcr.io/danny-avila/librechat-dev:latest
 
# # BUILD FROM LATEST IMAGE (NUMBERED RELEASE)
#   api:
#     image: ghcr.io/danny-avila/librechat:latest

# # BUILD FROM LATEST API IMAGE
#   api:
#     image: ghcr.io/danny-avila/librechat-dev-api:latest

# # BUILD FROM LATEST API IMAGE (NUMBERED RELEASE)
#   api:
#     image: ghcr.io/danny-avila/librechat-api:latest

# # ADD MONGO-EXPRESS
#   mongo-express:
#     image: mongo-express
#     container_name: mongo-express
#     environment:
#       ME_CONFIG_MONGODB_SERVER: mongodb
#       ME_CONFIG_BASICAUTH_USERNAME: admin
#       ME_CONFIG_BASICAUTH_PASSWORD: password
#     ports:
#       - '8081:8081'
#     depends_on:
#       - mongodb
#     restart: always

# # USE MONGODB V4.4.18 - FOR OLDER CPU WITHOUT AVX SUPPORT
#   mongodb:
#     image: mongo:4.4.18

# # DISABLE THE MONGODB CONTAINER - YOU NEED TO SET AN ALTERNATIVE MONGODB URI IN THE .ENV FILE
#   api:
#     environment:
#       - MONGO_URI=${MONGO_URI}
#   mongodb:
#     image: tianon/true
#     command: ""
#     entrypoint: ""

# # EXPOSE MONGODB PORTS - USE CAREFULLY, THIS MAKES YOUR DATABASE VULNERABLE TO ATTACKS
#   mongodb:
#     ports:
#       - 27018:27017

# # DISABLE MEILISEARCH
#   meilisearch:
#     profiles:
#       - donotstart

# # EXPOSE MEILISEARCH PORTS - DO NOT USE THE DEFAULT VALUE FOR THE MASTER KEY IF YOU DO THIS
#   meilisearch:
#     ports:
#       - 7700:7700

# # USE RAG API IMAGE WITH LOCAL EMBEDDINGS SUPPORT
#  rag_api:
#    image: ghcr.io/danny-avila/librechat-rag-api-dev:latest
# # For Linux user: 
#    extra_hosts:
#      - "host.docker.internal:host-gateway"

# # ADD OLLAMA
#  ollama:
#    image: ollama/ollama:latest
#    deploy:
#      resources:
#        reservations:
#          devices:
#            - driver: nvidia
#              capabilities: [compute, utility]
#    ports:
#      - "11434:11434"
#    volumes:
#      - ./ollama:/root/.ollama

# # ADD LITELLM BASIC - NEED TO CONFIGURE litellm-config.yaml, ONLY NEED ENV TO ENABLE REDIS FOR CACHING OR LANGFUSE FOR MONITORING
#  litellm:
#    image: ghcr.io/berriai/litellm:main-latest
#    volumes:
#      - ./litellm/litellm-config.yaml:/app/config.yaml
#      - ./litellm/application_default_credentials.json:/app/application_default_credentials.json # only if using Google Vertex
#    ports:
#      - "4000:8000"
#    command: [ "--config", "/app/config.yaml", "--port", "8000", "--num_workers", "8" ]
#    environment:
#      OPENAI_API_KEY: none ## needs to be set if ollama's openai api compatibility is used
#      GOOGLE_APPLICATION_CREDENTIALS: /app/application_default_credentials.json ## only if using Google Vertex
#      REDIS_HOST: redis
#      REDIS_PORT: 6379
#      REDIS_PASSWORD: RedisChangeMe
#      LANGFUSE_PUBLIC_KEY: pk-lf-RandomStringFromLangfuseWebInterface
#      LANGFUSE_SECRET_KEY: sk-lf-RandomStringFromLangfuseWebInterface
#      LANGFUSE_HOST: http://langfuse-server:3000

# # ADD LITELLM CACHING
#  redis:
#    image: redis:7-alpine
#    command:
#    - sh
#    - -c # this is to evaluate the $REDIS_PASSWORD from the env
#    - redis-server --appendonly yes --requirepass $$REDIS_PASSWORD ## $$ because of docker-compose
#    environment:
#      REDIS_PASSWORD: RedisChangeMe
#    volumes:
#    - ./redis:/data
  
# # ADD LITELLM MONITORING
#  langfuse-server:
#    image: ghcr.io/langfuse/langfuse:latest
#    depends_on:
#      - db
#    ports:
#      - "3000:3000"
#    environment:
#      - NODE_ENV=production
#      - DATABASE_URL=postgresql://postgres:PostgresChangeMe@db:5432/postgres
#      - NEXTAUTH_SECRET=ChangeMe
#      - SALT=ChangeMe
#      - NEXTAUTH_URL=http://localhost:3000
#      - TELEMETRY_ENABLED=${TELEMETRY_ENABLED:-true}
#      - NEXT_PUBLIC_SIGN_UP_DISABLED=${NEXT_PUBLIC_SIGN_UP_DISABLED:-false}
#      - LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES=${LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES:-false}
#  db:
#    image: postgres
#    restart: always
#    environment:
#      - POSTGRES_USER=postgres
#      - POSTGRES_PASSWORD=PostgresChangeMe
#      - POSTGRES_DB=postgres
#    volumes:
#      - ./postgres:/var/lib/postgresql/data
